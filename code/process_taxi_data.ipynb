{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to process original taxi trip data to count data.   \n",
    "At the end of project it will be merged into the main notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries to process parquet files and geospatial data\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to read and process parquet files from folder and return a dataframe\n",
    "def read_and_count_parquet(folder_path):\n",
    "    '''\n",
    "    INPUT: folder_path - path to folder containing parquet files\n",
    "    OUTPUT: saves the processed dataframe to csv file\n",
    "    '''\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".parquet\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_parquet(file_path)\n",
    "\n",
    "            # rename columns for yellow taxi data\n",
    "            if filename.split('_')[0] == 'yellow':\n",
    "                df = df.rename(columns={'tpep_pickup_datetime':'lpep_pickup_datetime',\n",
    "                                                           'tpep_dropoff_datetime':'lpep_dropoff_datetime'})\n",
    "            df = process_data(df)  # process the dataframe\n",
    "            try:\n",
    "                save_path = f'../data/processed_nyc_data/{filename.split(\".\")[0]}.csv'\n",
    "            except:\n",
    "                print('save_path is not defined')\n",
    "            save_path = save_path.replace('trip', 'count')\n",
    "            df.to_csv(save_path, index=False)  # save the dataframe to csv file\n",
    "            print(f'{filename} is processed')\n",
    "            \n",
    "    return 'Done!'\n",
    "\n",
    "# create a function to process the dataframe and return a counted dataframe\n",
    "def process_data(df):\n",
    "    '''\n",
    "    INPUT: df - dataframe of parquet files\n",
    "    OUTPUT: df - counted dataframe of parquet files\n",
    "    '''\n",
    "    # select columns that are needed\n",
    "    df = df[['lpep_pickup_datetime', 'passenger_count', \n",
    "              'PULocationID', 'DOLocationID', 'tip_amount', 'total_amount']]\n",
    "\n",
    "    # delete rows with values >263 in 'PULocationID' and 'DOLocationID' columns\n",
    "    df = df[(df['PULocationID'] <= 263) & (df['DOLocationID'] <= 263)]\n",
    "    # fill missing values in 'passenger_count' column with 1\n",
    "    df['passenger_count'] = df['passenger_count'].fillna(1)\n",
    "    # dropna in 'total_amount' and 'tip_amount' columns\n",
    "    df = df.dropna(subset=['total_amount','tip_amount'])\n",
    "    # calculate the trip_fee = Total_amount - Tip_amount\n",
    "    df['trip_fee'] = df['total_amount'] - df['tip_amount']\n",
    "\n",
    "\n",
    "    # delete columns that are not needed anymore\n",
    "    df = df.drop(columns=['total_amount','tip_amount'])\n",
    "    # delete rows with negative values and 0 in 'trip_fee' column\n",
    "    df = df[df['trip_fee'] > 0]\n",
    "\n",
    "    # count the number of trips in each day, hour, PULocationID and DOLocationID\n",
    "    df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])\n",
    "    df['day'] = df['lpep_pickup_datetime'].dt.day\n",
    "    df['hour'] = df['lpep_pickup_datetime'].dt.hour\n",
    "    count_df = df.groupby(['day','hour','PULocationID','DOLocationID']).count().reset_index()\n",
    "    \n",
    "    # calculate the average trip_fee in each day, hour, PULocationID and DOLocationID\n",
    "    count_df['trip_fee'] = df.groupby(['day','hour',\n",
    "                                       'PULocationID','DOLocationID']).mean().reset_index()['trip_fee']\n",
    "\n",
    "    # rename the column 'lpep_pickup_datetime' to 'trip_count'\n",
    "    count_df = count_df.rename(columns={'lpep_pickup_datetime':'trip_count'})\n",
    "\n",
    "    # calculate the passenger_cofficient = passenger_count / trip_count\n",
    "    # passenger_cofficient is the average number of passengers in each trip\n",
    "\n",
    "    count_df['passenger_cofficient'] = df.groupby(['day','hour',\n",
    "                                                    'PULocationID','DOLocationID']).mean().reset_index()['passenger_count']\n",
    "     \n",
    "    \n",
    "    return count_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useful columns: \n",
    "* lpep _pickup_datetime\n",
    "* passenger_count\n",
    "* PULocation\n",
    "* DOLocation\n",
    "* Tip_amount\n",
    "* Total_amount\n",
    "\n",
    "for:\n",
    "* passenger_cofficient = passenger_count / trip_count\n",
    "* trip_fee = Total_amount - Tip_amount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process parquet files from folder\n",
    "folder_path = '../data/NYC_taxi_data/'\n",
    "read_and_count_parquet(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the green and yellow taxi data\n",
    "for i in range(2017,2022):\n",
    "    df_green = pd.read_csv(f'../data/processed_nyc_data/green_countdata_{i}-12.csv')\n",
    "    df_yellow = pd.read_csv(f'../data/processed_nyc_data/yellow_countdata_{i}-12.csv')\n",
    "    \n",
    "    # merge the green and yellow taxi data by day, hour, PULocationID and DOLocationID\n",
    "    # which trip_count = yellow + green\n",
    "    # passenger_count = yellow + green\n",
    "    # trip_fee = (yellow * yellow_trip_fee + green * green_trip_fee) / (yellow + green)\n",
    "    # passenger_cofficient = (yellow * yellow_passenger_cofficient + green * green_passenger_cofficient) / (yellow + green)\n",
    "    df = pd.merge(df_green, df_yellow, how='outer', on=['day','hour','PULocationID','DOLocationID'])\n",
    "    df = df.fillna(0)\n",
    "    df['trip_count'] = df['trip_count_x'] + df['trip_count_y']\n",
    "    df['passenger_count'] = df['passenger_count_x'] + df['passenger_count_y']\n",
    "    df['trip_fee'] = round((df['trip_fee_x'] * df['trip_count_x'] + df['trip_fee_y'] * df['trip_count_y']) / df['trip_count'],2)  # round 2\n",
    "    df['passenger_cofficient'] = round((df['passenger_cofficient_x'] * df['trip_count_x'] + df['passenger_cofficient_y'] * df['trip_count_y']) / df['trip_count'], 2)  # round 2\n",
    "    df = df.drop(columns=['trip_count_x','trip_count_y','passenger_count_x','passenger_count_y',\n",
    "                            'trip_fee_x','trip_fee_y','passenger_cofficient_x','passenger_cofficient_y'])\n",
    "    \n",
    "    # save the dataframe to csv file\n",
    "    df.to_csv(f'../data/processed_nyc_data/countdata_{i}-12.csv', index=False)\n",
    "    print(f'countdata_{i}-12.csv is saved')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PTUA_Ass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73aa197a937c6d4ce912cf3eb748cc19d4a43b8337a43d316b8eed91cf78bf92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
